---
title: 'Visualization Project: Walmart store sales analysis'
author: "Sneha KK"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning = FALSE, message = FALSE,fig.width = 6,
 out.width="50%")

```

__Introduction:__

Sales analysis is an important aspect of running a store as we need to understand the factors that influence sales if we want to increase profit and customer satisfaction.
It provides insights into the past, present, and future performance and can be used to help forecast trends, identify opportunities for growth, and develop a strategic action plan for the stores.
The aim of this project is to analyze the sales of Walmart stores to find how 
different features impact the sales in a Walmart supermarket using exploratory data 
analysis and R visualizations.\

__Data set description:__\
The data set was downloaded from kaggle: \ https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting
It contains the historical sales data for 45 Walmart stores located in different 
regions, and each store contains a number of departments. The data is distributed 
in four csv files:\
1. stores.csv : type and size of stores\
2. train.csv: This is the historical training data, which covers to 2010-02-05 to 2012-11-01.The features represent store number,department number, date , weekly sales(sales for the given department in the given store) and isholiday(whether the week is a special holiday or not)\
3. test.csv: This file is identical to train.csv, except weekly sales column is absent.\
4.features.csv: This file contains additional data related to the store, department, and regional activity for the given dates. It contains features like store number,date, temperature, fuel price, markdown, CPI, unemployment rate,holidays\


__Project methodology:__\
The dataset was downloaded and checked for null values:


```{r include=FALSE}

library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
```

```{r,echo=FALSE}
test_df<-read.csv("C:/CMI Datascience/Sem1/VISU/test.csv")
train_df<-read.csv("C:/CMI Datascience/Sem1/VISU/train.csv")
feat_df<-read.csv("C:/CMI Datascience/Sem1/VISU/features.csv")
stores_df<-read.csv("C:/CMI Datascience/Sem1/VISU/stores.csv")

#check for null:
checkna<-function(df){
  apply(is.na(df),2,function(x) mean(x))
}
checkna(train_df)
checkna(test_df)
checkna(feat_df)
checkna(stores_df)  
#only markdown has null values.
```
Only markdown columns have many null values, because the stores offer promotional markdowns only on some days of the year.\

```{r,echo=FALSE}
options(repr.plot.width = 0.2, repr.plot.height =0.2)

tt<-train_df%>%group_by(Dept)%>% 
  summarise(total_count=n(),sales=mean(Weekly_Sales),.groups = 'drop')

```


Distribution of the weekly sales, log transformed: \
```{r,echo=FALSE}
#Counts of weekly sales (log)
ggplot(data=train_df,aes(x=Weekly_Sales))+geom_histogram(color='white',fill='purple')+scale_x_log10()+xlab('Weekly sales')+ggtitle('Weekly sales');
```

Mean weekly sales is approximately 16000 dollars.\
Number of holidays among the 115064 days in dataset:\

```{r,echo=FALSE}
#Sales during holiday weeks (log):
holidays <-train_df %>%filter(IsHoliday == T)
nrow(holidays)
ggplot(data=holidays,aes(x=Weekly_Sales))+geom_histogram(color='white',fill='purple')+scale_x_log10()+ggtitle('Holiday sales')+xlab('Sales')+ylab('count')
```

Mean holiday sales is approximately 17000 dollars.\
Department wise weekly sales:\
```{r,echo=FALSE}
#Department wise weekly sales
ggplot(data=tt,aes(x=Dept,y=sales))+geom_bar(stat='identity',fill='green')+ggtitle('Department wise weekly sales')+xlab('Department number')+ylab('Weekly sales')

```

Departments 92,95 and 38 have the highest weekly sales.\
Department wise mean sale amount:\
```{r,echo=FALSE}
#mean sale amount
ggplot(data=tt,aes(x=Dept,y=(sales/total_count)))+geom_bar(stat='identity',fill='red')
```

Department 65 has unusually high values, so let's remove it from our graph:\
```{r,echo=FALSE}
#department 65 has unusually high avg sales
td<-tt%>%filter(Dept!=65)
ggplot(data=td,aes(x=Dept,y=(sales/total_count)))+geom_bar(stat='identity',fill='red')
```

Departments 92,95,38 have the highest mean sales also.\
Let's view the mean sales amount for the three years:\
```{r,echo=FALSE}
train_df$year<-format(as.Date(train_df$Date),format="%Y")
tw<-train_df%>%group_by(year)%>% 
  summarise(sales=mean(Weekly_Sales),.groups = 'drop')
ggplot(data=train_df,aes(x=year,y=Weekly_Sales))+geom_bar(stat='identity',color='magenta')+xlab('year')+ylab('sales amount')+ggtitle('sales amount over the years')

```

Sales in 2011 is the highest and 2012 is the least.\
Variation of mean CPI over the years:\
```{r,echo=FALSE}
feat_df$year<-format(as.Date(feat_df$Date),format="%Y")
fg<-feat_df%>%group_by(year)%>% 
  summarise(cpi=mean(CPI,na.rm=T),Unemp=mean(Unemployment,na.rm=T),.groups = 'drop')
ggplot(data=fg,aes(x=year,y=cpi,fill=year))+geom_bar(stat='identity')+xlab('year')+ylab('mean cpi')+ggtitle('Mean Consumer Price Index over the years')
```

Mean Consumer Price index has an upward trend.\
Mean unemployment rate:\
```{r,echo=FALSE}
ggplot(data=fg,aes(x=year,y=Unemp,fill=year))+geom_bar(stat='identity')+xlab('year')+ylab('mean unemployment rate')+ggtitle('Mean Unemployment rate over the years')
```

Mean unemployment rate is decreasing over the years.\
Mean of the promotional markdowns offered:\
```{r,echo=FALSE}
feat_df<-feat_df%>%rowwise()%>%mutate(markdown = sum(MarkDown1,MarkDown2,MarkDown3,MarkDown4,MarkDown5, na.rm=TRUE))
mk<-feat_df%>%filter(markdown>0)
mkk<-mk%>%group_by(year)%>%summarise(markdown=mean(markdown,na.rm=T),.groups = 'drop')
ggplot(data=mkk,aes(x=year,y=markdown,fill=year))+geom_bar(stat='identity')+xlab('year')+ylab('Markdown')+ggtitle('Mean Markdown over the years')

```

Mean markdown was highest in 2011, almost same in 2012 and 2013.\

Store type wise sales:\
```{r,echo=FALSE}
tshr=train_df[seq(1,nrow(train_df),143),]
fs<-merge(tshr,feat_df,all=FALSE)
fst<-merge(fs,stores_df)
gp<-fst%>%group_by(across("Type"))%>%summarise(total_count=n(),.groups = 'drop')
gp <- gp%>% 
      mutate(perc = total_count / sum(total_count)) %>% 
      arrange(perc) %>%
      mutate(labels = scales::percent(perc))
ggplot(gp,aes_string(y='total_count',x="''",fill="Type"))+geom_bar(stat='identity')+coord_polar('y')+ggtitle('Pie plot of count of store type')+geom_text(aes(label = labels),position = position_stack(vjust = 0.5))+scale_fill_manual(values=c("purple","pink","yellow"))
  
```

Type A stores contributed to 51% of the sales, type B stores contributed to 39% of the sales and
type C stores contributed to only 10% of the sales.

```{r,echo=FALSE}
fst<-transform(fst,Type=as.character(Type))
ggplot(fst,aes_string(x="year",y="Weekly_Sales",fill="IsHoliday"))+geom_bar(stat='identity',position = 'dodge')+ggtitle(("Holiday-wise bar plot between sales and year"))
```

Total holiday sales is increasing over the years while the total working day sales is highest in 2011.\

```{r,echo=FALSE}
chris<-train_df[train_df$Date %in% c("2010-12-31","2011-12-30","2012-12-28"),]
bowl<-train_df[train_df$Date %in% c("2010-02-12","2011-02-11","2012-02-10"),]
labor<-train_df[train_df$Date %in% c("2010-09-10","2011-09-09","2012-09-07"),]
thank<-train_df[train_df$Date %in% c("2010-11-26","2011-11-25","2012-11-23"),]
chris<-chris%>%group_by(across("Date"))%>%summarise(sales=mean(Weekly_Sales))
bowl<-bowl%>%group_by(across("Date"))%>%summarise(sales=mean(Weekly_Sales))
labor<-labor%>%group_by(across("Date"))%>%summarise(sales=mean(Weekly_Sales))
thank<-thank%>%group_by(across("Date"))%>%summarise(sales=mean(Weekly_Sales))
chris$year<-format(as.Date(chris$Date),format="%Y")
bowl$year<-format(as.Date(bowl$Date),format="%Y")
labor$year<-format(as.Date(labor$Date),format="%Y")
thank$year<-format(as.Date(thank$Date),format="%Y")
n1=merge(labor,bowl,by='year')
n2=merge(chris,thank,by='year')

h=merge(n1,n2,by='year',all.x=TRUE)
colnames(h)<-c("year","datel","salesl","dateb","salesb","datec","salesc","datet","salest")
ggplot(h,aes(x=year))+geom_point(aes(y=salesc,color='red'),group=1)+geom_line(aes(y=salesc),color='red',group=1)+geom_point(aes(y=salesl,color='blue'),group=1)+geom_line(aes(y=salesl),color='blue',group=1)+geom_point(aes(y=salest,color='#FF9900'),group=1)+geom_line(aes(y=salest),color='#FF9900',group=1)+geom_point(aes(y=salesb,color='#990099'),group=1)+geom_line(aes(y=salesb),color='#990099',group=1)+
      ylab("Sales")+ggtitle("Holidays vs sales")+
     scale_color_manual(name='Holidays',values = c(
         'Christmas' = 'red',
         'Labor day' = 'blue','Thanksgiving'='#FF9900','Super bowl'='#990099')) +
      labs(color = 'Holidays')
```

Sales during thanks giving is the highest and sales during christmas is the least.
```{r,echo=FALSE}
ft<-merge(train_df,feat_df)
ft<-ft%>%rowwise()%>%mutate(markdown = sum(MarkDown1,MarkDown2,MarkDown3,MarkDown4,MarkDown5, na.rm=TRUE))
t<-select(ft,-Date,-MarkDown1,-MarkDown2,-MarkDown3,-MarkDown4,-MarkDown5)
t$IsHoliday<-ifelse(t$IsHoliday==TRUE,1,0)
t<-transform(t,year=as.numeric(year))
cc<-round(cor(t),2)
corrplot(cc) 

```

We can see that none of the variables have high correlation between them. Fuel price and year, markdown and year are positively correlated whereas Unemployment rate and CPI, CPI and stores and year and unemployment are negatively correlated.

__Dashboard__:\
A dashboard of visuals was created using RShiny containing the following panels :\
* Introduction\
* Univariate analysis: Analysis of frequencies of different variables using bar plot, pie chart for categorical and histogram for continuous variables.\
* Multivariate analysis: Analysing the relationship within factors using bar plots for categorical and categorical, categorical and continuous variables and scatter plot for analysis between continuous variables.\
* Year wise analysis: Multi variate graphs combined and colored by year.\
* Holiday wise analysis: This has two tab panels:\
  + One panel contained multivariate graphs that were combined and colored by holiday/working day.\
  + The second panel contained the line graphs of particular holidays.\
* Store type wise analysis: Multivariate graphs combined and colored by store type.\
Link to the dashboard: https://snehakk.shinyapps.io/visualization_project/

The dashboard helps us view our data in a consolidated format at one unified location. The interpretations drawn from the graphs helpd us understand the factors influencing sales amount and customer needs which in turn will lead to more profit and customer satisfaction.\

__Conclusions:__\
After detailed analysis and visualization of the Walmart sales data,we can infer the following :\
* Mean weakly sales amount in Walmart super market is approximately 16000 dollars and is slightly decreasing over the years while mean holiday sales amount is approximately 17000 dollars.\
* Departments 65,92,95,38 have the highest mean sales amount.\
* Mean consumer price index is increasing over the years while mean unemployment rate and mean markdown amount are decreasing over the years.\
* Mean markdown was highest in 2011, almost same in 2012 and 2013.\
* Type A stores contributed to 51% of the sales, type B stores contributed to 39% of the sales and
type C stores contributed to only 10% of the sales.\
* Total holiday sales is increasing over the years while the total working day sales is highest in 2011.\
* Sales during thanks giving is the highest and sales during christmas is the least.\
* Fuel price and year, markdown and year are positively correlated whereas Unemployment rate and CPI, CPI and stores and year and unemployment are negatively correlated.\

Hence, from Walmart sales data, we can conclude that lower CPI and higher markdown offers , investing in departments 65,92,95 and 38 would lead to an increase in sales profit.\
